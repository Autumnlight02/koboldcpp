/**
 * This file was auto-generated by openapi-typescript.
 * Do not make direct changes to the file.
 */

export interface paths {
    "/api/v1/config/max_context_length": {
        parameters: {
            query?: never;
            header?: never;
            path?: never;
            cookie?: never;
        };
        /** Retrieve the current max context length setting value that horde sees */
        get: {
            parameters: {
                query?: never;
                header?: never;
                path?: never;
                cookie?: never;
            };
            requestBody?: never;
            responses: {
                /** @description Successful request */
                200: {
                    headers: {
                        [name: string]: unknown;
                    };
                    content: {
                        "application/json": components["schemas"]["MaxContextLengthSetting"];
                    };
                };
            };
        };
        put?: never;
        post?: never;
        delete?: never;
        options?: never;
        head?: never;
        patch?: never;
        trace?: never;
    };
    "/api/v1/config/max_length": {
        parameters: {
            query?: never;
            header?: never;
            path?: never;
            cookie?: never;
        };
        /** Retrieve the current max length (amount to generate) setting value */
        get: {
            parameters: {
                query?: never;
                header?: never;
                path?: never;
                cookie?: never;
            };
            requestBody?: never;
            responses: {
                /** @description Successful request */
                200: {
                    headers: {
                        [name: string]: unknown;
                    };
                    content: {
                        "application/json": components["schemas"]["MaxLengthSetting"];
                    };
                };
            };
        };
        put?: never;
        post?: never;
        delete?: never;
        options?: never;
        head?: never;
        patch?: never;
        trace?: never;
    };
    "/api/v1/generate": {
        parameters: {
            query?: never;
            header?: never;
            path?: never;
            cookie?: never;
        };
        get?: never;
        put?: never;
        /**
         * Generate text with a specified prompt
         * @description Generates text given a prompt and generation settings.
         *
         *     Unspecified values are set to defaults.
         */
        post: {
            parameters: {
                query?: never;
                header?: never;
                path?: never;
                cookie?: never;
            };
            requestBody: {
                content: {
                    /** @example {
                     *       "max_context_length": 2048,
                     *       "max_length": 100,
                     *       "prompt": "Niko the kobold stalked carefully down the alley, his small scaly figure obscured by a dusky cloak that fluttered lightly in the cold winter breeze.",
                     *       "quiet": false,
                     *       "rep_pen": 1.1,
                     *       "rep_pen_range": 256,
                     *       "rep_pen_slope": 1,
                     *       "temperature": 0.5,
                     *       "tfs": 1,
                     *       "top_a": 0,
                     *       "top_k": 100,
                     *       "top_p": 0.9,
                     *       "typical": 1
                     *     } */
                    "application/json": components["schemas"]["GenerationInput"];
                };
            };
            responses: {
                /** @description Successful request */
                200: {
                    headers: {
                        [name: string]: unknown;
                    };
                    content: {
                        "application/json": components["schemas"]["GenerationOutput"];
                    };
                };
                /** @description Server is busy */
                503: {
                    headers: {
                        [name: string]: unknown;
                    };
                    content: {
                        "application/json": components["schemas"]["ServerBusyError"];
                    };
                };
            };
        };
        delete?: never;
        options?: never;
        head?: never;
        patch?: never;
        trace?: never;
    };
    "/api/v1/info/version": {
        parameters: {
            query?: never;
            header?: never;
            path?: never;
            cookie?: never;
        };
        /**
         * Current KoboldAI United API version
         * @description Returns the matching *KoboldAI* (United) version of the API that you are currently using. This is not the same as the KoboldCpp API version - this is used to feature match against KoboldAI United.
         */
        get: {
            parameters: {
                query?: never;
                header?: never;
                path?: never;
                cookie?: never;
            };
            requestBody?: never;
            responses: {
                /** @description Successful request */
                200: {
                    headers: {
                        [name: string]: unknown;
                    };
                    content: {
                        "application/json": components["schemas"]["BasicResult"];
                    };
                };
            };
        };
        put?: never;
        post?: never;
        delete?: never;
        options?: never;
        head?: never;
        patch?: never;
        trace?: never;
    };
    "/api/v1/model": {
        parameters: {
            query?: never;
            header?: never;
            path?: never;
            cookie?: never;
        };
        /**
         * Retrieve the current model string.
         * @description Gets the current model display name.
         */
        get: {
            parameters: {
                query?: never;
                header?: never;
                path?: never;
                cookie?: never;
            };
            requestBody?: never;
            responses: {
                /** @description Successful request */
                200: {
                    headers: {
                        [name: string]: unknown;
                    };
                    content: {
                        "application/json": components["schemas"]["BasicResult"];
                    };
                };
            };
        };
        put?: never;
        post?: never;
        delete?: never;
        options?: never;
        head?: never;
        patch?: never;
        trace?: never;
    };
    "/api/extra/true_max_context_length": {
        parameters: {
            query?: never;
            header?: never;
            path?: never;
            cookie?: never;
        };
        /**
         * Retrieve the actual max context length setting value set from the launcher
         * @description Retrieve the actual max context length setting value set from the launcher
         */
        get: {
            parameters: {
                query?: never;
                header?: never;
                path?: never;
                cookie?: never;
            };
            requestBody?: never;
            responses: {
                /** @description Successful request */
                200: {
                    headers: {
                        [name: string]: unknown;
                    };
                    content: {
                        "application/json": components["schemas"]["MaxContextLengthSetting"];
                    };
                };
            };
        };
        put?: never;
        post?: never;
        delete?: never;
        options?: never;
        head?: never;
        patch?: never;
        trace?: never;
    };
    "/api/extra/version": {
        parameters: {
            query?: never;
            header?: never;
            path?: never;
            cookie?: never;
        };
        /**
         * Retrieve the KoboldCpp backend version
         * @description Retrieve the KoboldCpp backend version
         */
        get: {
            parameters: {
                query?: never;
                header?: never;
                path?: never;
                cookie?: never;
            };
            requestBody?: never;
            responses: {
                /** @description Successful request */
                200: {
                    headers: {
                        [name: string]: unknown;
                    };
                    content: {
                        "application/json": components["schemas"]["KcppVersion"];
                    };
                };
            };
        };
        put?: never;
        post?: never;
        delete?: never;
        options?: never;
        head?: never;
        patch?: never;
        trace?: never;
    };
    "/api/extra/preloadstory": {
        parameters: {
            query?: never;
            header?: never;
            path?: never;
            cookie?: never;
        };
        /**
         * Retrieves the KoboldCpp preloaded story
         * @description Retrieves the KoboldCpp preloaded story, --preloadstory configures a prepared story json save file to be hosted on the server, which frontends (such as KoboldAI Lite) can access over the API.
         */
        get: {
            parameters: {
                query?: never;
                header?: never;
                path?: never;
                cookie?: never;
            };
            requestBody?: never;
            responses: {
                /** @description Successful request */
                200: {
                    headers: {
                        [name: string]: unknown;
                    };
                    content: {
                        "application/json": unknown;
                    };
                };
            };
        };
        put?: never;
        post?: never;
        delete?: never;
        options?: never;
        head?: never;
        patch?: never;
        trace?: never;
    };
    "/api/extra/perf": {
        parameters: {
            query?: never;
            header?: never;
            path?: never;
            cookie?: never;
        };
        /**
         * Retrieve the KoboldCpp recent performance information
         * @description Retrieve the KoboldCpp recent performance information
         */
        get: {
            parameters: {
                query?: never;
                header?: never;
                path?: never;
                cookie?: never;
            };
            requestBody?: never;
            responses: {
                /** @description Successful request */
                200: {
                    headers: {
                        [name: string]: unknown;
                    };
                    content: {
                        "application/json": components["schemas"]["KcppPerf"];
                    };
                };
            };
        };
        put?: never;
        post?: never;
        delete?: never;
        options?: never;
        head?: never;
        patch?: never;
        trace?: never;
    };
    "/api/extra/generate/stream": {
        parameters: {
            query?: never;
            header?: never;
            path?: never;
            cookie?: never;
        };
        get?: never;
        put?: never;
        /**
         * Generate text with a specified prompt. SSE streamed results.
         * @description Generates text given a prompt and generation settings, with SSE streaming.
         *
         *     Unspecified values are set to defaults.
         *
         *     SSE streaming establishes a persistent connection, returning ongoing process in the form of message events.
         *
         *     ```
         *     event: message
         *     data: {data}
         *
         *     ```
         */
        post: {
            parameters: {
                query?: never;
                header?: never;
                path?: never;
                cookie?: never;
            };
            requestBody: {
                content: {
                    /** @example {
                     *       "prompt": "Niko the kobold stalked carefully down the alley, his small scaly figure obscured by a dusky cloak that fluttered lightly in the cold winter breeze.",
                     *       "temperature": 0.5,
                     *       "top_p": 0.9
                     *     } */
                    "application/json": components["schemas"]["GenerationInput"];
                };
            };
            responses: {
                /** @description Successful request */
                200: {
                    headers: {
                        [name: string]: unknown;
                    };
                    content: {
                        "application/json": components["schemas"]["GenerationOutput"];
                    };
                };
                /** @description Server is busy */
                503: {
                    headers: {
                        [name: string]: unknown;
                    };
                    content: {
                        "application/json": components["schemas"]["ServerBusyError"];
                    };
                };
            };
        };
        delete?: never;
        options?: never;
        head?: never;
        patch?: never;
        trace?: never;
    };
    "/api/extra/generate/check": {
        parameters: {
            query?: never;
            header?: never;
            path?: never;
            cookie?: never;
        };
        /**
         * Poll the incomplete results of the currently ongoing text generation.
         * @description Poll the incomplete results of the currently ongoing text generation. Will not work when multiple requests are in queue.
         */
        get: {
            parameters: {
                query?: never;
                header?: never;
                path?: never;
                cookie?: never;
            };
            requestBody?: never;
            responses: {
                /** @description Successful request */
                200: {
                    headers: {
                        [name: string]: unknown;
                    };
                    content: {
                        "application/json": components["schemas"]["GenerationOutput"];
                    };
                };
            };
        };
        put?: never;
        /**
         * Poll the incomplete results of the currently ongoing text generation. Supports multiuser mode.
         * @description Poll the incomplete results of the currently ongoing text generation. A unique genkey previously submitted allows polling even in multiuser mode.
         */
        post: {
            parameters: {
                query?: never;
                header?: never;
                path?: never;
                cookie?: never;
            };
            requestBody?: {
                content: {
                    /** @example {
                     *       "genkey": "KCPP2342"
                     *     } */
                    "application/json": {
                        /** @description A unique key used to identify this generation while it is in progress. */
                        genkey?: string;
                    };
                };
            };
            responses: {
                /** @description Successful request */
                200: {
                    headers: {
                        [name: string]: unknown;
                    };
                    content: {
                        "application/json": components["schemas"]["GenerationOutput"];
                    };
                };
            };
        };
        delete?: never;
        options?: never;
        head?: never;
        patch?: never;
        trace?: never;
    };
    "/api/extra/tokencount": {
        parameters: {
            query?: never;
            header?: never;
            path?: never;
            cookie?: never;
        };
        get?: never;
        put?: never;
        /**
         * Counts the number of tokens in a string.
         * @description Counts the number of tokens in a string.
         */
        post: {
            parameters: {
                query?: never;
                header?: never;
                path?: never;
                cookie?: never;
            };
            requestBody: {
                content: {
                    /** @example {
                     *       "prompt": "Hello, my name is Niko."
                     *     } */
                    "application/json": {
                        /** @description The string to be tokenized. */
                        prompt?: string;
                    };
                };
            };
            responses: {
                /** @description Successful request */
                200: {
                    headers: {
                        [name: string]: unknown;
                    };
                    content: {
                        "application/json": components["schemas"]["ValueResult"];
                    };
                };
            };
        };
        delete?: never;
        options?: never;
        head?: never;
        patch?: never;
        trace?: never;
    };
    "/api/extra/abort": {
        parameters: {
            query?: never;
            header?: never;
            path?: never;
            cookie?: never;
        };
        get?: never;
        put?: never;
        /**
         * Aborts the currently ongoing text generation.
         * @description Aborts the currently ongoing text generation. Does not work when multiple requests are in queue.
         */
        post: {
            parameters: {
                query?: never;
                header?: never;
                path?: never;
                cookie?: never;
            };
            requestBody?: {
                content: {
                    /** @example {
                     *       "genkey": "KCPP2342"
                     *     } */
                    "application/json": {
                        /** @description A unique key used to identify this generation while it is in progress. */
                        genkey?: string;
                    };
                };
            };
            responses: {
                /** @description Successful request */
                200: {
                    headers: {
                        [name: string]: unknown;
                    };
                    content: {
                        "application/json": {
                            /** @description Whether the abort was successful. */
                            success?: boolean;
                        };
                    };
                };
            };
        };
        delete?: never;
        options?: never;
        head?: never;
        patch?: never;
        trace?: never;
    };
    "/api/extra/transcribe": {
        parameters: {
            query?: never;
            header?: never;
            path?: never;
            cookie?: never;
        };
        get?: never;
        put?: never;
        /**
         * Uses Whisper to perform a Speech-To-Text transcription.
         * @description Uses Whisper to perform a Speech-To-Text transcription.
         */
        post: {
            parameters: {
                query?: never;
                header?: never;
                path?: never;
                cookie?: never;
            };
            requestBody: {
                content: {
                    /** @example {
                     *       "prompt": "",
                     *       "audio_data": "base64_wav_data"
                     *     } */
                    "application/json": {
                        /** @description Base64 respresentation of a 16-bit 16kHz wave file to be transcribed to text. */
                        audio_data?: string;
                    };
                };
            };
            responses: {
                /** @description Successful request */
                200: {
                    headers: {
                        [name: string]: unknown;
                    };
                    content: {
                        "application/json": components["schemas"]["ValueResult"];
                    };
                };
            };
        };
        delete?: never;
        options?: never;
        head?: never;
        patch?: never;
        trace?: never;
    };
    "/sdapi/v1/sd-models": {
        parameters: {
            query?: never;
            header?: never;
            path?: never;
            cookie?: never;
        };
        /**
         * Gets a list of image generation models
         * @description Gets a list of image generation models. For koboldcpp, only one model will be returned. If no model is loaded, the list is empty.
         */
        get: {
            parameters: {
                query?: never;
                header?: never;
                path?: never;
                cookie?: never;
            };
            requestBody?: never;
            responses: {
                /** @description Successful request */
                200: {
                    headers: {
                        [name: string]: unknown;
                    };
                    content: {
                        "application/json": unknown;
                    };
                };
            };
        };
        put?: never;
        post?: never;
        delete?: never;
        options?: never;
        head?: never;
        patch?: never;
        trace?: never;
    };
    "/sdapi/v1/options": {
        parameters: {
            query?: never;
            header?: never;
            path?: never;
            cookie?: never;
        };
        /**
         * Gets configuration info for image generation
         * @description Gets configuration info for image generation, used to get loaded model name in A1111.
         */
        get: {
            parameters: {
                query?: never;
                header?: never;
                path?: never;
                cookie?: never;
            };
            requestBody?: never;
            responses: {
                /** @description Successful request */
                200: {
                    headers: {
                        [name: string]: unknown;
                    };
                    content: {
                        "application/json": unknown;
                    };
                };
            };
        };
        put?: never;
        post?: never;
        delete?: never;
        options?: never;
        head?: never;
        patch?: never;
        trace?: never;
    };
    "/sdapi/v1/samplers": {
        parameters: {
            query?: never;
            header?: never;
            path?: never;
            cookie?: never;
        };
        /**
         * Gets a list of supported samplers
         * @description Gets a list of supported samplers.
         */
        get: {
            parameters: {
                query?: never;
                header?: never;
                path?: never;
                cookie?: never;
            };
            requestBody?: never;
            responses: {
                /** @description Successful request */
                200: {
                    headers: {
                        [name: string]: unknown;
                    };
                    content: {
                        "application/json": unknown;
                    };
                };
            };
        };
        put?: never;
        post?: never;
        delete?: never;
        options?: never;
        head?: never;
        patch?: never;
        trace?: never;
    };
    "/sdapi/v1/txt2img": {
        parameters: {
            query?: never;
            header?: never;
            path?: never;
            cookie?: never;
        };
        get?: never;
        put?: never;
        /**
         * Generates an image from a text prompt
         * @description Generates an image from a text prompt, and returns a base64 encoded png.
         */
        post: {
            parameters: {
                query?: never;
                header?: never;
                path?: never;
                cookie?: never;
            };
            requestBody?: {
                content: {
                    /** @example {
                     *       "prompt": "picture of a kobold, high quality HD render",
                     *       "negative_prompt": "ugly, deformed, censored",
                     *       "cfg_scale": 5,
                     *       "steps": 20,
                     *       "width": 512,
                     *       "height": 512,
                     *       "seed": -1,
                     *       "sampler_name": "Euler a"
                     *     } */
                    "application/json": {
                        prompt?: string;
                        negative_prompt?: string;
                        cfg_scale?: number;
                        steps?: number;
                        width?: number;
                        height?: number;
                        seed?: number;
                        sampler_name?: string;
                    };
                };
            };
            responses: {
                /** @description Successful request */
                200: {
                    headers: {
                        [name: string]: unknown;
                    };
                    content: {
                        "application/json": {
                            /** @description A base64 string containing the encoded PNG of the generated image. */
                            images?: string;
                            /** @description Not used. Will be empty. */
                            parameters?: Record<string, never>;
                            /** @description Not used. Will be empty. */
                            info?: string;
                        };
                    };
                };
            };
        };
        delete?: never;
        options?: never;
        head?: never;
        patch?: never;
        trace?: never;
    };
    "/sdapi/v1/img2img": {
        parameters: {
            query?: never;
            header?: never;
            path?: never;
            cookie?: never;
        };
        get?: never;
        put?: never;
        /**
         * Transforms an existing image into a new image
         * @description Transforms an existing image into a new image, guided by a text prompt, and returns a base64 encoded png.
         */
        post: {
            parameters: {
                query?: never;
                header?: never;
                path?: never;
                cookie?: never;
            };
            requestBody?: {
                content: {
                    /** @example {
                     *       "prompt": "picture of a kobold, high quality HD render",
                     *       "negative_prompt": "ugly, deformed, censored",
                     *       "cfg_scale": 5,
                     *       "steps": 20,
                     *       "width": 512,
                     *       "height": 512,
                     *       "seed": -1,
                     *       "sampler_name": "Euler a",
                     *       "denoising_strength": 0.6,
                     *       "init_images": [
                     *         "base64_image_data"
                     *       ]
                     *     } */
                    "application/json": {
                        prompt?: string;
                        negative_prompt?: string;
                        cfg_scale?: number;
                        steps?: number;
                        width?: number;
                        height?: number;
                        seed?: number;
                        sampler_name?: string;
                        denoising_strength?: number;
                        init_images?: unknown[];
                    };
                };
            };
            responses: {
                /** @description Successful request */
                200: {
                    headers: {
                        [name: string]: unknown;
                    };
                    content: {
                        "application/json": {
                            /** @description A base64 string containing the encoded PNG of the generated image. */
                            images?: string;
                            /** @description Not used. Will be empty. */
                            parameters?: Record<string, never>;
                            /** @description Not used. Will be empty. */
                            info?: string;
                        };
                    };
                };
            };
        };
        delete?: never;
        options?: never;
        head?: never;
        patch?: never;
        trace?: never;
    };
    "/sdapi/v1/interrogate": {
        parameters: {
            query?: never;
            header?: never;
            path?: never;
            cookie?: never;
        };
        get?: never;
        put?: never;
        /**
         * Generates a short text caption describing an image
         * @description Generates a short text caption describing an image.
         */
        post: {
            parameters: {
                query?: never;
                header?: never;
                path?: never;
                cookie?: never;
            };
            requestBody?: {
                content: {
                    /** @example {
                     *       "image": "base64_image_data",
                     *       "model": "clip"
                     *     } */
                    "application/json": {
                        /** @description A base64 string containing the encoded PNG of the image. */
                        image?: string;
                        /** @description Not used. */
                        model?: string;
                    };
                };
            };
            responses: {
                /** @description Successful request */
                200: {
                    headers: {
                        [name: string]: unknown;
                    };
                    content: {
                        "application/json": {
                            /** @description A short text description of the image. */
                            caption?: string;
                        };
                    };
                };
            };
        };
        delete?: never;
        options?: never;
        head?: never;
        patch?: never;
        trace?: never;
    };
    "/v1/completions": {
        parameters: {
            query?: never;
            header?: never;
            path?: never;
            cookie?: never;
        };
        get?: never;
        put?: never;
        /**
         * Generates text continuations given a prompt. Please refer to OpenAI documentation
         * @description Generates text continuations given a prompt.
         *
         *     This is an OpenAI compatibility endpoint.
         *
         *      Please refer to OpenAI documentation at [https://platform.openai.com/docs/api-reference/completions](https://platform.openai.com/docs/api-reference/completions)
         */
        post: {
            parameters: {
                query?: never;
                header?: never;
                path?: never;
                cookie?: never;
            };
            requestBody?: never;
            responses: never;
        };
        delete?: never;
        options?: never;
        head?: never;
        patch?: never;
        trace?: never;
    };
    "/v1/chat/completions": {
        parameters: {
            query?: never;
            header?: never;
            path?: never;
            cookie?: never;
        };
        get?: never;
        put?: never;
        /**
         * Generates a response from a list of messages. Please refer to OpenAI documentation
         * @description Given a list of messages comprising a conversation, the model will return a response.
         *
         *      This is an OpenAI compatibility endpoint.
         *
         *      Please refer to OpenAI documentation at [https://platform.openai.com/docs/api-reference/chat](https://platform.openai.com/docs/api-reference/chat)
         */
        post: {
            parameters: {
                query?: never;
                header?: never;
                path?: never;
                cookie?: never;
            };
            requestBody?: never;
            responses: never;
        };
        delete?: never;
        options?: never;
        head?: never;
        patch?: never;
        trace?: never;
    };
    "/v1/models": {
        parameters: {
            query?: never;
            header?: never;
            path?: never;
            cookie?: never;
        };
        /**
         * List and describe the various models available in the API. Please refer to OpenAI documentation
         * @description List and describe the various models available in the API.
         *
         *      This is an OpenAI compatibility endpoint.
         *
         *      Please refer to OpenAI documentation at [https://platform.openai.com/docs/api-reference/models](https://platform.openai.com/docs/api-reference/models)
         */
        get: {
            parameters: {
                query?: never;
                header?: never;
                path?: never;
                cookie?: never;
            };
            requestBody?: never;
            responses: never;
        };
        put?: never;
        post?: never;
        delete?: never;
        options?: never;
        head?: never;
        patch?: never;
        trace?: never;
    };
    "/v1/audio/transcriptions": {
        parameters: {
            query?: never;
            header?: never;
            path?: never;
            cookie?: never;
        };
        get?: never;
        put?: never;
        /**
         * Transcribes a wav file with speech to text using loaded Whisper model. Please refer to OpenAI documentation
         * @description Transcribes a wav file with speech to text using loaded Whisper model.
         *
         *      This is an OpenAI compatibility endpoint.
         *
         *      Please refer to OpenAI documentation at [https://platform.openai.com/docs/api-reference/audio/createTranscription](https://platform.openai.com/docs/api-reference/audio/createTranscription)
         */
        post: {
            parameters: {
                query?: never;
                header?: never;
                path?: never;
                cookie?: never;
            };
            requestBody?: never;
            responses: never;
        };
        delete?: never;
        options?: never;
        head?: never;
        patch?: never;
        trace?: never;
    };
}
export type webhooks = Record<string, never>;
export interface components {
    schemas: {
        BasicError: {
            msg: string;
            type: string;
        };
        BasicResult: {
            result: components["schemas"]["BasicResultInner"];
        };
        BasicResultInner: {
            result: string;
        };
        GenerationInput: {
            /** @description Maximum number of tokens to send to the model. */
            max_context_length?: number;
            /** @description Number of tokens to generate. */
            max_length?: number;
            /** @description This is the submission. */
            prompt: string;
            /** @description Base repetition penalty value. */
            rep_pen?: number;
            /** @description Repetition penalty range. */
            rep_pen_range?: number;
            /** @description Sampler order to be used. If N is the length of this array, then N must be greater than or equal to 6 and the array must be a permutation of the first N non-negative integers. */
            sampler_order?: number[];
            /** @description RNG seed to use for sampling. If not specified, the global RNG will be used. */
            sampler_seed?: number;
            /** @description An array of string sequences where the API will stop generating further tokens. The returned text WILL contain the stop sequence. */
            stop_sequence?: string[];
            /** @description Temperature value. */
            temperature?: number;
            /** @description Tail free sampling value. */
            tfs?: number;
            /** @description Top-a sampling value. */
            top_a?: number;
            /** @description Top-k sampling value. */
            top_k?: number;
            /** @description Top-p sampling value. */
            top_p?: number;
            /** @description Min-p sampling value. */
            min_p?: number;
            /** @description Typical sampling value. */
            typical?: number;
            /**
             * @description If true, prevents the EOS token from being generated (Ban EOS).
             * @default false
             */
            use_default_badwordsids: boolean;
            /**
             * @description If greater than 0, uses dynamic temperature. Dynamic temperature range will be between Temp+Range and Temp-Range. If less or equal to 0 , uses static temperature.
             * @default 0
             */
            dynatemp_range: number;
            /**
             * @description Modifies temperature behavior. If greater than 0 uses smoothing factor.
             * @default 0
             */
            smoothing_factor: number;
            /**
             * @description Exponent used in dynatemp.
             * @default 1
             */
            dynatemp_exponent: number;
            /** @description KoboldCpp ONLY. Sets the mirostat mode, 0=disabled, 1=mirostat_v1, 2=mirostat_v2 */
            mirostat?: number;
            /** @description KoboldCpp ONLY. Mirostat tau value. */
            mirostat_tau?: number;
            /** @description KoboldCpp ONLY. Mirostat eta value. */
            mirostat_eta?: number;
            /** @description KoboldCpp ONLY. A unique genkey set by the user. When checking a polled-streaming request, use this key to be able to fetch pending text even if multiuser is enabled. */
            genkey?: string;
            /** @description KoboldCpp ONLY. A string containing the GBNF grammar to use. */
            grammar?: string;
            /**
             * @description KoboldCpp ONLY. If true, retains the previous generation's grammar state, otherwise it is reset on new generation.
             * @default false
             */
            grammar_retain_state: boolean;
            /** @description KoboldCpp ONLY. If set, forcefully appends this string to the beginning of any submitted prompt text. If resulting context exceeds the limit, forcefully overwrites text from the beginning of the main prompt until it can fit. Useful to guarantee full memory insertion even when you cannot determine exact token count. */
            memory?: string;
            /** @description KoboldCpp ONLY. If set, takes an array of base64 encoded strings, each one representing an image to be processed. */
            images?: unknown[];
            /**
             * @description KoboldCpp ONLY. If true, also removes detected stop_sequences from the output and truncates all text after them.
             * @default false
             */
            trim_stop: boolean;
            /**
             * @description KoboldCpp ONLY. If true, prints special tokens as text for GGUF models
             * @default false
             */
            render_special: boolean;
            /**
             * @description KoboldCpp ONLY. If true, allows EOS token to be generated, but does not stop generation. Not recommended unless you know what you are doing.
             * @default false
             */
            bypass_eos: boolean;
            /** @description An array of string sequences to remove from model vocab. All matching tokens with matching substrings are removed. */
            banned_tokens?: string[];
            /**
             * @description KoboldCpp ONLY. An dictionary of key-value pairs, which indicate the token IDs (int) and logit bias (float) to apply for that token. Up to 16 value can be provided.
             * @default {}
             * @example {
             *       "2": -20,
             *       "145": -1.4,
             *       "3105": 3.2
             *     }
             */
            logit_bias: Record<string, never>;
            /** @description KoboldCpp ONLY. DRY multiplier value, 0 to disable. */
            dry_multiplier?: number;
            /** @description KoboldCpp ONLY. DRY base value. */
            dry_base?: number;
            /** @description KoboldCpp ONLY. DRY allowed length value. */
            dry_allowed_length?: number;
            /** @description An array of string sequence breakers for DRY. */
            dry_sequence_breakers?: string[];
        };
        GenerationOutput: {
            /** @description Array of generated outputs. */
            results: components["schemas"]["GenerationResult"][];
        };
        GenerationResult: {
            /** @description Generated output as plain text. */
            text: string;
        };
        MaxContextLengthSetting: {
            value: number;
        };
        MaxLengthSetting: {
            value: number;
        };
        ServerBusyError: {
            detail: components["schemas"]["BasicError"];
        };
        ValueResult: {
            value: number;
        };
        KcppVersion: {
            result?: string;
            version: string;
        };
        KcppPerf: {
            /** @description Last processing time in seconds. */
            last_process?: number;
            /** @description Last evaluation time in seconds. */
            last_eval?: number;
            /** @description Last token count. */
            last_token_count?: number;
            /** @description Last generation seed used. */
            last_seed?: number;
            /** @description Total requests generated since startup. */
            total_gens?: number;
            /** @description Reason the generation stopped. INVALID=-1, OUT_OF_TOKENS=0, EOS_TOKEN_HIT=1, CUSTOM_STOPPER=2 */
            stop_reason?: number;
            /** @description Length of generation queue. */
            queue?: number;
            /** @description Status of backend, busy or idle. */
            idle?: number;
            /** @description Status of embedded horde worker. If it's too high, may have crashed. */
            hordeexitcounter?: number;
            /** @description Seconds that the server has been running for. */
            uptime?: number;
        };
    };
    responses: never;
    parameters: never;
    requestBodies: never;
    headers: never;
    pathItems: never;
}
export type $defs = Record<string, never>;
export type operations = Record<string, never>;
